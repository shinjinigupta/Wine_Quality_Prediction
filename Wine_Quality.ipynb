{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# White-wine data reading and cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[fixed acidity: double, volatile acidity: double, citric acid: double, residual sugar: double, chlorides: double, free sulfur dioxide: double, total sulfur dioxide: double, density: double, pH: double, sulphates: double, alcohol: double, quality: int]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import the white-wine file which is in CSV format \n",
    "from pyspark.sql import SparkSession\n",
    "spark=SparkSession.builder.getOrCreate()\n",
    "dataFrame=spark.read.option(\"delimiter\", \";\").option(\"inferSchema\", \"true\").option(\"header\",\"true\").csv(r\"C:\\Users\\varsh\\OneDrive\\Desktop\\MSDA\\SEM2\\MACHINE_LEARNING\\Project\\datasets\\winequality-white.csv\")\n",
    "dataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------------+-----------+--------------+---------+-------------------+--------------------+-------+----+---------+-------+-------+\n",
      "|fixed_acidity|volatile_acidity|citric_acid|residual_sugar|chlorides|free_sulfur_dioxide|total_sulfur_dioxide|density|  pH|sulphates|alcohol|quality|\n",
      "+-------------+----------------+-----------+--------------+---------+-------------------+--------------------+-------+----+---------+-------+-------+\n",
      "|          7.0|            0.27|       0.36|          20.7|    0.045|               45.0|               170.0|  1.001| 3.0|     0.45|    8.8|      6|\n",
      "|          6.3|             0.3|       0.34|           1.6|    0.049|               14.0|               132.0|  0.994| 3.3|     0.49|    9.5|      6|\n",
      "|          8.1|            0.28|        0.4|           6.9|     0.05|               30.0|                97.0| 0.9951|3.26|     0.44|   10.1|      6|\n",
      "+-------------+----------------+-----------+--------------+---------+-------------------+--------------------+-------+----+---------+-------+-------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#checking and renaming headers into single value:\n",
    "dataFrame = dataFrame.withColumnRenamed('fixed acidity', 'fixed_acidity')\n",
    "dataFrame = dataFrame.withColumnRenamed('volatile acidity', 'volatile_acidity')\n",
    "dataFrame = dataFrame.withColumnRenamed('citric acid', 'citric_acid')\n",
    "dataFrame = dataFrame.withColumnRenamed('free sulfur dioxide', 'free_sulfur_dioxide')\n",
    "dataFrame = dataFrame.withColumnRenamed('residual sugar', 'residual_sugar')\n",
    "dataFrame = dataFrame.withColumnRenamed('total sulfur dioxide', 'total_sulfur_dioxide')\n",
    "dataFrame.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- fixed_acidity: double (nullable = true)\n",
      " |-- volatile_acidity: double (nullable = true)\n",
      " |-- citric_acid: double (nullable = true)\n",
      " |-- residual_sugar: double (nullable = true)\n",
      " |-- chlorides: double (nullable = true)\n",
      " |-- free_sulfur_dioxide: double (nullable = true)\n",
      " |-- total_sulfur_dioxide: double (nullable = true)\n",
      " |-- density: double (nullable = true)\n",
      " |-- pH: double (nullable = true)\n",
      " |-- sulphates: double (nullable = true)\n",
      " |-- alcohol: double (nullable = true)\n",
      " |-- quality: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#checking for categorical values\n",
    "dataFrame.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of non-distinct data is : 4898\n",
      "The number of distinct data is : 3961\n",
      "Therefore, the number of duplicates are: 937\n",
      "After dropping the duplicates, the count of the dictinct data is: 3961\n"
     ]
    }
   ],
   "source": [
    "#Checking and removing of duplicates:\n",
    "print(\"The number of non-distinct data is :\",dataFrame.count())\n",
    "print(\"The number of distinct data is :\",dataFrame.distinct().count()) \n",
    "print(\"Therefore, the number of duplicates are:\",dataFrame.count()-dataFrame.distinct().count()) \n",
    "dataFrame=dataFrame.dropDuplicates()\n",
    "print(\"After dropping the duplicates, the count of the dictinct data is:\",dataFrame.count()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fixed_acidity': 0,\n",
       " 'volatile_acidity': 0,\n",
       " 'citric_acid': 0,\n",
       " 'residual_sugar': 0,\n",
       " 'chlorides': 0,\n",
       " 'free_sulfur_dioxide': 0,\n",
       " 'total_sulfur_dioxide': 0,\n",
       " 'density': 0,\n",
       " 'pH': 0,\n",
       " 'sulphates': 0,\n",
       " 'alcohol': 0,\n",
       " 'quality': 0}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking for nulls or missing values:\n",
    "nulls = {col:dataFrame.filter(dataFrame[col].isNull()).count() for col in dataFrame.columns}\n",
    "nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fixed_acidity',\n",
       " 'volatile_acidity',\n",
       " 'citric_acid',\n",
       " 'residual_sugar',\n",
       " 'chlorides',\n",
       " 'free_sulfur_dioxide',\n",
       " 'total_sulfur_dioxide',\n",
       " 'density',\n",
       " 'pH',\n",
       " 'sulphates',\n",
       " 'alcohol',\n",
       " 'label']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a user defined function to convert the interger values of 'quality' column into binary values such as 0 and 1.\n",
    "import pyspark.sql.functions as func\n",
    "def pred_col(feat1):\n",
    "    return func.when((func.col(feat1)>6),1).otherwise(0)\n",
    "\n",
    "quality_transformed=dataFrame.withColumn('label',pred_col('quality'))\n",
    "\n",
    "df=quality_transformed[['fixed_acidity',\n",
    "'volatile_acidity',\n",
    "'citric_acid',\n",
    "'residual_sugar',\n",
    "'chlorides',\n",
    "'free_sulfur_dioxide',\n",
    "'total_sulfur_dioxide',\n",
    "'density',\n",
    "'pH',\n",
    "'sulphates',\n",
    "'alcohol','label']]\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|      feature_vector|label|\n",
      "+--------------------+-----+\n",
      "|[6.7,0.23,0.26,1....|    0|\n",
      "|[7.4,0.2,0.36,1.2...|    0|\n",
      "|[6.7,0.17,0.5,2.1...|    0|\n",
      "|[6.4,0.24,0.32,14...|    0|\n",
      "|[7.2,0.55,0.09,1....|    0|\n",
      "|[6.6,0.24,0.29,2....|    0|\n",
      "|[6.5,0.26,0.28,12...|    0|\n",
      "|[7.4,0.24,0.31,8....|    0|\n",
      "|[7.2,0.37,0.15,2....|    1|\n",
      "|[7.5,0.23,0.32,9....|    0|\n",
      "|[9.0,0.31,0.48,6....|    0|\n",
      "|[6.2,0.27,0.49,1....|    0|\n",
      "|[7.6,0.26,0.58,7....|    0|\n",
      "|[10.0,0.23,0.27,1...|    0|\n",
      "|[6.8,0.31,0.09,1....|    0|\n",
      "|[7.7,0.24,0.31,1....|    0|\n",
      "|[6.3,0.18,0.22,1....|    0|\n",
      "|[7.6,0.1,0.33,1.0...|    0|\n",
      "|[6.6,0.45,0.43,7....|    0|\n",
      "|[7.1,0.27,0.28,1....|    0|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Feature engineering: convert the features into feature vectors.\n",
    "from pyspark.ml.linalg import Vector\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "vectorAssembler=VectorAssembler(inputCols=['fixed_acidity',\n",
    " 'volatile_acidity',\n",
    " 'citric_acid',\n",
    " 'residual_sugar',\n",
    " 'chlorides',\n",
    " 'free_sulfur_dioxide',\n",
    " 'total_sulfur_dioxide',\n",
    " 'density',\n",
    " 'pH',\n",
    " 'sulphates',\n",
    " 'alcohol'],outputCol='feature_vector')\n",
    "\n",
    "df = vectorAssembler.transform(df)\n",
    "df = df.select(['feature_vector', 'label'])\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardize the feature-vector values.\n",
    "from pyspark.ml.feature import StandardScaler  \n",
    "Scalerizer=StandardScaler().setInputCol(\"feature_vector\").setOutputCol(\"features\")\n",
    "df=Scalerizer.fit(df).transform(df)\n",
    "df=df.select(['features','label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2793, 1168)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#split the data into training and test data.\n",
    "train,test=df.randomSplit([0.7,0.3]) # spitting the dataframe data into training data(70%) and test data(30%)\n",
    "train.count(),test.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# White-wine Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseVector(11, {0: 0.0187, 1: 0.0878, 2: 0.0258, 4: 0.0428, 5: 0.0866, 6: 0.0382, 7: 0.0131, 8: 0.0497, 9: 0.0192, 10: 0.6182})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a decision tree regression model using the training dataset.\n",
    "from pyspark.ml.regression import DecisionTreeRegressor\n",
    "DTRegModel=DecisionTreeRegressor(featuresCol='features',labelCol='label').fit(train)\n",
    "DTRegModel.featureImportances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+\n",
      "|            features|label|          prediction|\n",
      "+--------------------+-----+--------------------+\n",
      "|[6.57545821272352...|    0|  0.5302013422818792|\n",
      "|[7.15225279278698...|    0|0.007312614259597806|\n",
      "|[7.26761170879968...|    0| 0.22727272727272727|\n",
      "|[7.26761170879968...|    0|0.007312614259597806|\n",
      "|[7.26761170879968...|    0|0.007312614259597806|\n",
      "|[7.38297062481237...|    0| 0.07246376811594203|\n",
      "|[7.61368845683776...|    0| 0.32432432432432434|\n",
      "|[7.61368845683776...|    0|0.007312614259597806|\n",
      "|[8.07512412088853...|    1|                 0.0|\n",
      "|[7.03689387677429...|    1|   0.746268656716418|\n",
      "|[7.61368845683776...|    0|0.007312614259597806|\n",
      "|[8.30584195291392...|    0| 0.06153846153846154|\n",
      "|[9.11335436500277...|    0|  0.4714285714285714|\n",
      "|[9.45943111304085...|    0|0.007312614259597806|\n",
      "|[7.03689387677429...|    0|0.007312614259597806|\n",
      "|[7.84440628886314...|    0|  0.3340909090909091|\n",
      "|[7.84440628886314...|    0|0.041666666666666664|\n",
      "|[7.95976520487584...|    0|0.007312614259597806|\n",
      "|[8.07512412088853...|    0|  0.5137614678899083|\n",
      "|[8.65191870095200...|    0|0.041666666666666664|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Test the model with the test dataset for predictions.\n",
    "DTReg_predictions=DTRegModel.transform(test)\n",
    "DTReg_predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The r-square value of DecisionTreeRegressor is 16.22%\n"
     ]
    }
   ],
   "source": [
    "#Check the r2-score value.\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "dt_evaluator = RegressionEvaluator(metricName='r2')\n",
    "dt_r2 = dt_evaluator.evaluate(DTReg_predictions)\n",
    "print(f'The r-square value of DecisionTreeRegressor is {round((dt_r2*100),2)}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The rmse value of DecisionTreeRegressor is 36.64%\n"
     ]
    }
   ],
   "source": [
    "#check the root mean squared error value.\n",
    "dt_evaluator = RegressionEvaluator(metricName='rmse')\n",
    "dt_rmse = dt_evaluator.evaluate(DTReg_predictions)\n",
    "print(f'The rmse value of DecisionTreeRegressor is {round((dt_rmse*100),2)}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# White-wine Classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseVector(11, {0: 0.0252, 1: 0.0076, 4: 0.0418, 5: 0.1046, 6: 0.0176, 8: 0.0443, 10: 0.7588})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a decision tree classification model using the training dataset.\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "\n",
    "DTClassModel=DecisionTreeClassifier(featuresCol='features',labelCol='label').fit(train)\n",
    "DTClassModel.featureImportances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+----------+\n",
      "|            features|label|prediction|\n",
      "+--------------------+-----+----------+\n",
      "|[6.57545821272352...|    0|       1.0|\n",
      "|[7.15225279278698...|    0|       0.0|\n",
      "|[7.26761170879968...|    0|       0.0|\n",
      "|[7.26761170879968...|    0|       0.0|\n",
      "|[7.26761170879968...|    0|       0.0|\n",
      "|[7.38297062481237...|    0|       0.0|\n",
      "|[7.61368845683776...|    0|       0.0|\n",
      "|[7.61368845683776...|    0|       0.0|\n",
      "|[8.07512412088853...|    1|       0.0|\n",
      "|[7.03689387677429...|    1|       1.0|\n",
      "|[7.61368845683776...|    0|       0.0|\n",
      "|[8.30584195291392...|    0|       0.0|\n",
      "|[9.11335436500277...|    0|       0.0|\n",
      "|[9.45943111304085...|    0|       0.0|\n",
      "|[7.03689387677429...|    0|       0.0|\n",
      "|[7.84440628886314...|    0|       0.0|\n",
      "|[7.84440628886314...|    0|       0.0|\n",
      "|[7.95976520487584...|    0|       0.0|\n",
      "|[8.07512412088853...|    0|       1.0|\n",
      "|[8.65191870095200...|    0|       0.0|\n",
      "+--------------------+-----+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Test the model with the test dataset for predictions\n",
    "DTClass_predictions=DTClassModel.transform(test)\n",
    "DTClass_predictions.select(\"features\",\"label\",\"prediction\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The auc value of Decision Tree Classifier Modelis 29.44%\n"
     ]
    }
   ],
   "source": [
    "#check the areaUnderROC value.\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "dt_evaluator = BinaryClassificationEvaluator(metricName='areaUnderROC')\n",
    "dt_auroc = dt_evaluator.evaluate(DTClass_predictions)\n",
    "print(f'The auc value of Decision Tree Classifier Modelis {round((dt_auroc*100),2)}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The aupr value of Decision Tree Model is 13.66%\n"
     ]
    }
   ],
   "source": [
    "#check the areaUnderPR value.\n",
    "dt_evaluator = BinaryClassificationEvaluator(metricName='areaUnderPR')\n",
    "dt_aupr = dt_evaluator.evaluate(DTClass_predictions)\n",
    "print(f'The aupr value of Decision Tree Model is {round((dt_aupr*100),2)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creation of confusion matrix\n",
    "truePositive = DTClass_predictions[(DTClass_predictions[\"label\"] == 1) & (DTClass_predictions['prediction']==1)].count()\n",
    "trueNegative = DTClass_predictions[(DTClass_predictions[\"label\"] == 0) & (DTClass_predictions['prediction']== 0)].count()\n",
    "falsePositive = DTClass_predictions[(DTClass_predictions[\"label\"] == 0) & (DTClass_predictions['prediction']== 1)].count()\n",
    "falseNegative = DTClass_predictions[(DTClass_predictions[\"label\"] == 1) & (DTClass_predictions['prediction']== 0)].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the accuracy is 81.42%\n"
     ]
    }
   ],
   "source": [
    "#Measuring the accuracy of the classification model\n",
    "accuracy=float((truePositive+trueNegative) /(DTClass_predictions.count()))\n",
    "print(\"the accuracy is {0}%\".format( round( accuracy*100,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the recall rate is 41.45%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Measuring the recall rate of the classification model\n",
    "recall = float(truePositive)/(truePositive + falseNegative)\n",
    "print(\"the recall rate is {0}%\".format( round( recall*100,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the precision value is 54.8%\n"
     ]
    }
   ],
   "source": [
    "#Measuring the precision of the classification model\n",
    "precision = float(truePositive)/(truePositive + falsePositive)\n",
    "print(\"the precision value is {0}%\".format( round( precision*100,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The error rate is 18.58%\n"
     ]
    }
   ],
   "source": [
    "Error_rate = (1-accuracy)*100\n",
    "print(\"The error rate is {0}%\".format( round( Error_rate,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Red-wine data reading and cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[fixed acidity: double, volatile acidity: double, citric acid: double, residual sugar: double, chlorides: double, free sulfur dioxide: double, total sulfur dioxide: double, density: double, pH: double, sulphates: double, alcohol: double, quality: int]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import the red-wine file which is in CSV format\n",
    "from pyspark.sql import SparkSession\n",
    "spark=SparkSession.builder.getOrCreate()\n",
    "dataFrame1=spark.read.option(\"delimiter\", \",\").option(\"inferSchema\", \"true\").option(\"header\",\"true\").csv(r\"C:\\Users\\varsh\\OneDrive\\Desktop\\MSDA\\SEM2\\MACHINE_LEARNING\\Project\\datasets\\winequality-red.csv\")\n",
    "dataFrame1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------------+-----------+--------------+---------+-------------------+--------------------+-------+----+---------+-------+-------+\n",
      "|fixed_acidity|volatile_acidity|citric_acid|residual_sugar|chlorides|free_sulfur_dioxide|total_sulfur_dioxide|density|  pH|sulphates|alcohol|quality|\n",
      "+-------------+----------------+-----------+--------------+---------+-------------------+--------------------+-------+----+---------+-------+-------+\n",
      "|          7.4|             0.7|        0.0|           1.9|    0.076|               11.0|                34.0| 0.9978|3.51|     0.56|    9.4|      5|\n",
      "|          7.8|            0.88|        0.0|           2.6|    0.098|               25.0|                67.0| 0.9968| 3.2|     0.68|    9.8|      5|\n",
      "|          7.8|            0.76|       0.04|           2.3|    0.092|               15.0|                54.0|  0.997|3.26|     0.65|    9.8|      5|\n",
      "+-------------+----------------+-----------+--------------+---------+-------------------+--------------------+-------+----+---------+-------+-------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#checking and renaming headers into single value:\n",
    "dataFrame1 = dataFrame1.withColumnRenamed('fixed acidity', 'fixed_acidity')\n",
    "dataFrame1 = dataFrame1.withColumnRenamed('volatile acidity', 'volatile_acidity')\n",
    "dataFrame1 = dataFrame1.withColumnRenamed('citric acid', 'citric_acid')\n",
    "dataFrame1 = dataFrame1.withColumnRenamed('free sulfur dioxide', 'free_sulfur_dioxide')\n",
    "dataFrame1 = dataFrame1.withColumnRenamed('residual sugar', 'residual_sugar')\n",
    "dataFrame1 = dataFrame1.withColumnRenamed('total sulfur dioxide', 'total_sulfur_dioxide')\n",
    "dataFrame1.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- fixed_acidity: double (nullable = true)\n",
      " |-- volatile_acidity: double (nullable = true)\n",
      " |-- citric_acid: double (nullable = true)\n",
      " |-- residual_sugar: double (nullable = true)\n",
      " |-- chlorides: double (nullable = true)\n",
      " |-- free_sulfur_dioxide: double (nullable = true)\n",
      " |-- total_sulfur_dioxide: double (nullable = true)\n",
      " |-- density: double (nullable = true)\n",
      " |-- pH: double (nullable = true)\n",
      " |-- sulphates: double (nullable = true)\n",
      " |-- alcohol: double (nullable = true)\n",
      " |-- quality: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#checking for categorical values\n",
    "dataFrame1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of non-distinct data is : 1599\n",
      "The number of distinct data is : 1359\n",
      "Therefore, the number of duplicates are: 240\n",
      "After dropping the duplicates, the count of the dictinct data is: 1359\n"
     ]
    }
   ],
   "source": [
    "#Checking and removing of duplicates:\n",
    "print(\"The number of non-distinct data is :\",dataFrame1.count())\n",
    "print(\"The number of distinct data is :\",dataFrame1.distinct().count()) \n",
    "print(\"Therefore, the number of duplicates are:\",dataFrame1.count()-dataFrame1.distinct().count()) \n",
    "dataFrame1=dataFrame1.dropDuplicates()\n",
    "print(\"After dropping the duplicates, the count of the dictinct data is:\",dataFrame1.count()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fixed_acidity': 0,\n",
       " 'volatile_acidity': 0,\n",
       " 'citric_acid': 0,\n",
       " 'residual_sugar': 0,\n",
       " 'chlorides': 0,\n",
       " 'free_sulfur_dioxide': 0,\n",
       " 'total_sulfur_dioxide': 0,\n",
       " 'density': 0,\n",
       " 'pH': 0,\n",
       " 'sulphates': 0,\n",
       " 'alcohol': 0,\n",
       " 'quality': 0}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking for nulls or missing values:\n",
    "nulls = {col:dataFrame1.filter(dataFrame1[col].isNull()).count() for col in dataFrame1.columns}\n",
    "nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fixed_acidity',\n",
       " 'volatile_acidity',\n",
       " 'citric_acid',\n",
       " 'residual_sugar',\n",
       " 'chlorides',\n",
       " 'free_sulfur_dioxide',\n",
       " 'total_sulfur_dioxide',\n",
       " 'density',\n",
       " 'pH',\n",
       " 'sulphates',\n",
       " 'alcohol',\n",
       " 'label']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a user defined function to convert the interger values of 'quality' column into binary values such as 0 and 1.\n",
    "import pyspark.sql.functions as func\n",
    "def pred_col(feat1):\n",
    "    return func.when((func.col(feat1)>6),1).otherwise(0)\n",
    "\n",
    "quality_transformed=dataFrame1.withColumn('label',pred_col('quality'))\n",
    "\n",
    "df1=quality_transformed[['fixed_acidity',\n",
    "'volatile_acidity',\n",
    "'citric_acid',\n",
    "'residual_sugar',\n",
    "'chlorides',\n",
    "'free_sulfur_dioxide',\n",
    "'total_sulfur_dioxide',\n",
    "'density',\n",
    "'pH',\n",
    "'sulphates',\n",
    "'alcohol','label']]\n",
    "df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|      feature_vector|label|\n",
      "+--------------------+-----+\n",
      "|[8.9,0.61,0.49,2....|    0|\n",
      "|[8.9,0.59,0.5,2.0...|    0|\n",
      "|[8.1,0.87,0.0,3.3...|    0|\n",
      "|[11.0,0.2,0.48,2....|    0|\n",
      "|[6.1,0.21,0.4,1.4...|    0|\n",
      "|[8.8,0.44,0.49,2....|    0|\n",
      "|[8.0,0.43,0.36,2....|    0|\n",
      "|[10.2,0.34,0.48,2...|    1|\n",
      "|[8.8,0.33,0.41,5....|    1|\n",
      "|[7.5,0.57,0.08,2....|    0|\n",
      "|[7.8,0.815,0.01,2...|    0|\n",
      "|[7.8,0.76,0.04,2....|    0|\n",
      "|[9.9,0.35,0.41,2....|    0|\n",
      "|[10.7,0.9,0.34,6....|    0|\n",
      "|[7.3,0.67,0.02,2....|    0|\n",
      "|[6.9,0.685,0.0,2....|    0|\n",
      "|[7.8,0.5,0.17,1.6...|    0|\n",
      "|[9.7,0.31,0.47,1....|    0|\n",
      "|[8.9,0.84,0.34,1....|    0|\n",
      "|[6.6,0.725,0.2,7....|    0|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Feature engineering: convert the features into feature vectors.\n",
    "from pyspark.ml.linalg import Vector\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "vectorAssembler=VectorAssembler(inputCols=['fixed_acidity',\n",
    " 'volatile_acidity',\n",
    " 'citric_acid',\n",
    " 'residual_sugar',\n",
    " 'chlorides',\n",
    " 'free_sulfur_dioxide',\n",
    " 'total_sulfur_dioxide',\n",
    " 'density',\n",
    " 'pH',\n",
    " 'sulphates',\n",
    " 'alcohol'],outputCol='feature_vector')\n",
    "\n",
    "df1 = vectorAssembler.transform(df1)\n",
    "df1 = df1.select(['feature_vector', 'label'])\n",
    "\n",
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|            features|label|\n",
      "+--------------------+-----+\n",
      "|[5.12380669213203...|    0|\n",
      "|[5.12380669213203...|    0|\n",
      "|[4.66323979845724...|    0|\n",
      "|[6.33279478802835...|    0|\n",
      "|[3.51182256427027...|    0|\n",
      "|[5.06623583042268...|    0|\n",
      "|[4.60566893674789...|    0|\n",
      "|[5.87222789435356...|    1|\n",
      "|[5.06623583042268...|    1|\n",
      "|[4.31781462820115...|    0|\n",
      "|[4.4905272133292,...|    0|\n",
      "|[4.4905272133292,...|    0|\n",
      "|[5.69951530922552...|    0|\n",
      "|[6.16008220290031...|    0|\n",
      "|[4.20267290478245...|    0|\n",
      "|[3.97238945794506...|    0|\n",
      "|[4.4905272133292,...|    0|\n",
      "|[5.58437358580682...|    0|\n",
      "|[5.12380669213203...|    0|\n",
      "|[3.79967687281701...|    0|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Standardize the feature-vector values.\n",
    "from pyspark.ml.feature import StandardScaler   #can be done once the feature vector is created\n",
    "Scalerizer=StandardScaler().setInputCol(\"feature_vector\").setOutputCol(\"features\")\n",
    "df1=Scalerizer.fit(df1).transform(df1)\n",
    "df1=df1.select(['features','label'])\n",
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(949, 410)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#split the data into training and test data.\n",
    "train,test=df1.randomSplit([0.7,0.3]) # spitting the dataframe data into training data(70%) and test data(30%)\n",
    "train.count(),test.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Red-wine regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseVector(11, {0: 0.0562, 1: 0.1197, 2: 0.0383, 3: 0.1453, 5: 0.0347, 7: 0.0341, 8: 0.0424, 9: 0.1551, 10: 0.3742})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a decision tree regression model using the training dataset.\n",
    "from pyspark.ml.regression import DecisionTreeRegressor\n",
    "DTRegModel=DecisionTreeRegressor(featuresCol='features',labelCol='label').fit(train)\n",
    "DTRegModel.featureImportances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+\n",
      "|            features|label|          prediction|\n",
      "+--------------------+-----+--------------------+\n",
      "|[4.31781462820115...|    0| 0.06451612903225806|\n",
      "|[4.20267290478245...|    0| 0.06451612903225806|\n",
      "|[6.16008220290031...|    0|0.005934718100890208|\n",
      "|[5.12380669213203...|    0|0.005934718100890208|\n",
      "|[4.83595238358529...|    1|                 1.0|\n",
      "|[7.13878685195924...|    0| 0.04477611940298507|\n",
      "|[2.87854308546743...|    0|                0.08|\n",
      "|[4.37538548991050...|    1|                0.08|\n",
      "|[5.00866496871333...|    0|0.005934718100890208|\n",
      "|[5.06623583042268...|    0| 0.04477611940298507|\n",
      "|[4.77838152187594...|    0| 0.06451612903225806|\n",
      "|[5.00866496871333...|    0|0.005934718100890208|\n",
      "|[5.64194444751617...|    1|0.005934718100890208|\n",
      "|[5.23894841555073...|    0| 0.06451612903225806|\n",
      "|[5.75708617093487...|    0| 0.14285714285714285|\n",
      "|[3.85724773452636...|    0| 0.06451612903225806|\n",
      "|[5.29651927726008...|    0|                 0.0|\n",
      "|[5.92979875606291...|    0|0.005934718100890208|\n",
      "|[5.98736961777226...|    0|0.005934718100890208|\n",
      "|[3.62696428768896...|    0| 0.06451612903225806|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Test the model with the test data for predictions.\n",
    "DTReg_predictions=DTRegModel.transform(test)\n",
    "DTReg_predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The r-square value of DecisionTreeRegressor is 13.91%\n"
     ]
    }
   ],
   "source": [
    "#Check the r2-score value.\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "dt_evaluator = RegressionEvaluator(metricName='r2')\n",
    "dt_r2 = dt_evaluator.evaluate(DTReg_predictions)\n",
    "print(f'The r-square value of DecisionTreeRegressor is {round((dt_r2*100),2)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The rmse value of DecisionTreeRegressor is 29.56%\n"
     ]
    }
   ],
   "source": [
    "#check the root mean squared error value.\n",
    "dt_evaluator = RegressionEvaluator(metricName='rmse')\n",
    "dt_rmse = dt_evaluator.evaluate(DTReg_predictions)\n",
    "print(f'The rmse value of DecisionTreeRegressor is {round((dt_rmse*100),2)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Red-wine Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a decision tree classification model using the training dataset.\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "\n",
    "DTClassModel=DecisionTreeClassifier(featuresCol='features',labelCol='label').fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+----------+\n",
      "|            features|label|prediction|\n",
      "+--------------------+-----+----------+\n",
      "|[4.31781462820115...|    0|       0.0|\n",
      "|[4.20267290478245...|    0|       0.0|\n",
      "|[6.16008220290031...|    0|       0.0|\n",
      "|[5.12380669213203...|    0|       0.0|\n",
      "|[4.83595238358529...|    1|       1.0|\n",
      "|[7.13878685195924...|    0|       0.0|\n",
      "|[2.87854308546743...|    0|       0.0|\n",
      "|[4.37538548991050...|    1|       0.0|\n",
      "|[5.00866496871333...|    0|       0.0|\n",
      "|[5.06623583042268...|    0|       0.0|\n",
      "|[4.77838152187594...|    0|       0.0|\n",
      "|[5.00866496871333...|    0|       0.0|\n",
      "|[5.64194444751617...|    1|       0.0|\n",
      "|[5.23894841555073...|    0|       0.0|\n",
      "|[5.75708617093487...|    0|       0.0|\n",
      "|[3.85724773452636...|    0|       0.0|\n",
      "|[5.29651927726008...|    0|       0.0|\n",
      "|[5.92979875606291...|    0|       0.0|\n",
      "|[5.98736961777226...|    0|       0.0|\n",
      "|[3.62696428768896...|    0|       0.0|\n",
      "+--------------------+-----+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Test the model with the test dataset for predictions\n",
    "DTClass_predictions=DTClassModel.transform(test)\n",
    "DTClass_predictions.select(\"features\",\"label\",\"prediction\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The auc value of Decision Tree Classifier Modelis 44.33%\n"
     ]
    }
   ],
   "source": [
    "#check the areaUnderROC value\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "dt_evaluator = BinaryClassificationEvaluator(metricName='areaUnderROC')\n",
    "dt_auroc = dt_evaluator.evaluate(DTClass_predictions)\n",
    "print(f'The auc value of Decision Tree Classifier Modelis {round((dt_auroc*100),2)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The aupr value of Decision Tree Model is 32.18%\n"
     ]
    }
   ],
   "source": [
    "#check the areaUnderPR value.\n",
    "dt_evaluator = BinaryClassificationEvaluator(metricName='areaUnderPR')\n",
    "dt_aupr = dt_evaluator.evaluate(DTClass_predictions)\n",
    "print(f'The aupr value of Decision Tree Model is {round((dt_aupr*100),2)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creation of confusion matrix\n",
    "truePositive = DTClass_predictions[(DTClass_predictions[\"label\"] == 1) & (DTClass_predictions['prediction']==1)].count()\n",
    "trueNegative = DTClass_predictions[(DTClass_predictions[\"label\"] == 0) & (DTClass_predictions['prediction']== 0)].count()\n",
    "falsePositive = DTClass_predictions[(DTClass_predictions[\"label\"] == 0) & (DTClass_predictions['prediction']== 1)].count()\n",
    "falseNegative = DTClass_predictions[(DTClass_predictions[\"label\"] == 1) & (DTClass_predictions['prediction']== 0)].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the accuracy is 89.27%\n"
     ]
    }
   ],
   "source": [
    "#Measuring the accuracy of the classification model\n",
    "accuracy=float((truePositive+trueNegative) /(DTClass_predictions.count()))\n",
    "print(\"the accuracy is {0}%\".format( round( accuracy*100,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the recall rate is 48.94%\n"
     ]
    }
   ],
   "source": [
    "#Measuring the recall rate of the classification model\n",
    "recall = float(truePositive)/(truePositive + falseNegative)\n",
    "print(\"the recall rate is {0}%\".format( round( recall*100,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the precision value is 53.49%\n"
     ]
    }
   ],
   "source": [
    "#Measuring the precision of the classification model\n",
    "precision = float(truePositive)/(truePositive + falsePositive)\n",
    "print(\"the precision value is {0}%\".format( round( precision*100,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The error rate is 10.73%\n"
     ]
    }
   ],
   "source": [
    "Error_rate = (1-accuracy)*100\n",
    "print(\"The error rate is {0}%\".format( round( Error_rate,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
